{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотеки PyTorch.\n",
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ряд вспомогательных функций для проверки заданий.\n",
    "\n",
    "def custom_compare(x, y):\n",
    "    if str(x) != str(y):\n",
    "        raise RuntimeError(f'Ожидаемое значение: {y}. Фактическое: {x}')\n",
    "        \n",
    "def to_list(x, precision=2):\n",
    "    return [round(x, precision) for x in x.tolist()]\n",
    "\n",
    "def to_list_m(m, precision=2):\n",
    "    res = []\n",
    "    \n",
    "    for l in m.tolist():\n",
    "        res.append([round(x, precision) for x in l])\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e13210",
   "metadata": {},
   "source": [
    "# Вектора и матрицы в PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1_solution(x):\n",
    "    \"\"\"\n",
    "    Принимает на вход вектор численных значений и вычисляет на его основе единственное значение.\n",
    "    \n",
    "    Аргументы:\n",
    "        x: Вектор, который имеет тип torch.Tensor.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Вектор (torch.Tensor), состоящий из одного числа — значения, которое\n",
    "        является результатом выполнения описанного вычисления.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1_test():\n",
    "    vect_example_1 = torch.tensor([0, 1], dtype=torch.float)\n",
    "    res_example_1 = -0.85\n",
    "    \n",
    "    custom_compare(round(function_1_solution(vect_example_1).item(), 2), res_example_1)\n",
    "    \n",
    "    vect_example_2 = torch.tensor([0, 3.14159], dtype=torch.float)\n",
    "    res_example_2 = -0.91\n",
    "    \n",
    "    custom_compare(round(function_1_solution(vect_example_2).item(), 2), res_example_2)\n",
    "    \n",
    "    vect_example_3 = torch.tensor([6, 2, 3, 1.1], dtype=torch.float)\n",
    "    res_example_3 = 0.54\n",
    "    \n",
    "    custom_compare(round(function_1_solution(vect_example_3).item(), 2), res_example_3)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4958c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_1_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9855f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2_solution(x, y):\n",
    "    \"\"\"\n",
    "    Принимает на вход два вектора численных значений и вычисляет на их основе новый вектор.\n",
    "    \n",
    "    Аргументы:\n",
    "        x: Вектор, который имеет тип torch.Tensor.\n",
    "        y: Вектор, который имеет тип torch.Tensor.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Вектор (torch.Tensor), полученный из исходных векторов по заданному правилу.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2_test():\n",
    "    x_example_1 = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "    y_example_1 = torch.tensor([1, 1, 1], dtype=torch.float)\n",
    "    \n",
    "    res_example_1 = [0.33, 0.67, 1.0, 0.17, 0.17, 0.17]\n",
    "    \n",
    "    custom_compare(to_list(function_2_solution(x_example_1, y_example_1)),\n",
    "                   res_example_1)\n",
    "    \n",
    "    x_example_2 = torch.tensor([2, 1, 9, 34], dtype=torch.float)\n",
    "    y_example_2 = torch.tensor([22, 17, -1], dtype=torch.float)\n",
    "    \n",
    "    res_example_2 = [0.05, 0.03, 0.24, 0.89, 0.48, 0.37, -0.02]\n",
    "    \n",
    "    custom_compare(to_list(function_2_solution(x_example_2, y_example_2)),\n",
    "                   res_example_2)\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_2_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3_solution(x, y):\n",
    "    \"\"\"\n",
    "    Принимает на вход два вектора численных значений и вычисляет\n",
    "    на их основе матрицу по заданному правилу.\n",
    "    \n",
    "    Аргументы:\n",
    "        x: Вектор, который имеет тип torch.Tensor.\n",
    "        y: Вектор, который имеет тип torch.Tensor.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Матрица (torch.Tensor), полученная из исходных векторов по заданному правилу.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256da65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_3_test():\n",
    "    x_example_1 = torch.tensor([1, 2.71828], dtype=torch.float)\n",
    "    y_example_1 = torch.tensor([2, 3, 4], dtype=torch.float)\n",
    "    \n",
    "    res_example_1 = [[0.0, 0.0, 0.0],\n",
    "                     [4.0, 9.0, 16.0]]\n",
    "    \n",
    "    custom_compare(to_list_m(function_3_solution(x_example_1, y_example_1)),\n",
    "                   res_example_1)\n",
    "    \n",
    "    x_example_2 = torch.tensor([72, 7.2, 2.8, 5.6], dtype=torch.float)\n",
    "    y_example_2 = torch.tensor([11, 32, 4.1, -8, 1.7, 3.2, -4.9], dtype=torch.float)\n",
    "    \n",
    "    res_example_2 = [[517.48, 4379.31, 71.89, 273.71, 12.36, 43.79, 102.68],\n",
    "                     [238.86, 2021.46, 33.18, 126.34, 5.71, 20.21, 47.4],\n",
    "                     [124.58, 1054.33, 17.31, 65.9, 2.98, 10.54, 24.72],\n",
    "                     [208.45, 1764.11, 28.96, 110.26, 4.98, 17.64, 41.36]]\n",
    "    \n",
    "    custom_compare(to_list_m(function_3_solution(x_example_2, y_example_2)),\n",
    "                   res_example_2)\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_3_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e6af4c",
   "metadata": {},
   "source": [
    "# Функции потерь и функции активации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2887c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_solution(x):\n",
    "    \"\"\"\n",
    "    Принимает на вход вектор фактических значений предсказываемой характеристики,\n",
    "    вектор предсказанных значений характеристики и вычисляет на их основе значение MAE.\n",
    "    \n",
    "    Аргументы:\n",
    "        y: Вектор фактических значений предсказываемой характеристики. Имеет тип данных torch.Tensor.\n",
    "        y_pred: Вектор предсказанных моделью значений характеристики. Имеет тип данных torch.Tensor.\n",
    "                Предсказание, которое содержится на i-й позиции вектора y_pred соответствует\n",
    "                фактическому значению на i-й позиции вектора y.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Вектор (torch.Tensor), состоящий из одного числа — значения\n",
    "        MAE для представленных данных.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb57de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_test():\n",
    "    y_example_1 = torch.tensor([1, -1, 1, 1], dtype=torch.float)\n",
    "    y_pred_example_1 = torch.tensor([1, -1, -1, -1], dtype=torch.float)\n",
    "    \n",
    "    res_example_1 = 1.0\n",
    "    \n",
    "    custom_compare(round(mae_solution(y_example_1, y_pred_example_1).item(), 2),\n",
    "                   res_example_1)\n",
    "    \n",
    "    y_example_2 = torch.tensor([10, 20, -31, 4, -5, 7, -9], dtype=torch.float)\n",
    "    y_pred_example_2 = torch.tensor([3, 25, -35, 0, 10, 7, -5], dtype=torch.float)\n",
    "    \n",
    "    res_example_2 = 5.57\n",
    "    \n",
    "    custom_compare(round(mae_solution(y_example_2, y_pred_example_2).item(), 2),\n",
    "                   res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590af78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c308a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_general_solution(x):\n",
    "    \"\"\"\n",
    "    Принимает на вход набор векторов, которые необходимо предсказать для объектов из выборки,\n",
    "    набор векторов, которые были предсказаны для объектов из выборки,\n",
    "    и вычисляет на их основе значение MAE.\n",
    "    \n",
    "    Аргументы:\n",
    "        y: Набор векторов, которые необходимо предсказать для объектов из выборки.\n",
    "           Набор представляется в виде матрицы (torch.Tensor) размера d x k,\n",
    "           где d — количество объектов в выборке, а k — размер вектора,\n",
    "           который необходимо предсказать для каждого объекта.\n",
    "        y_pred: Набор векторов, которые были предсказаны для объектов из выборки.\n",
    "                Набор представляется в виде матрицы (torch.Tensor) размера d x k,\n",
    "                где d — количество объектов в выборке, а k — размер вектора,\n",
    "                который необходимо предсказать для каждого объекта.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Вектор (torch.Tensor), состоящий из одного числа — значения\n",
    "        $MAE$ для представленных данных.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b76bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_general_test():\n",
    "    y_example_1 = torch.tensor([[1, -1], [1, 1]], dtype=torch.float)\n",
    "    y_pred_example_1 = torch.tensor([[1, -1], [-1, -1]], dtype=torch.float)\n",
    "    \n",
    "    res_example_1 = 1.0\n",
    "    \n",
    "    custom_compare(round(mae_general_solution(y_example_1, y_pred_example_1).item(), 2),\n",
    "                   res_example_1)\n",
    "    \n",
    "    y_example_2 = torch.tensor([[10, 22, -3], [11, 28, 0], [1, -1, 11], [22, 39, -7]], dtype=torch.float)\n",
    "    y_pred_example_2 = torch.tensor([[11, 20, 5], [5, 30, -2], [1, -1, 0], [18, 30, -7]], dtype=torch.float)\n",
    "    \n",
    "    res_example_2 = 3.75\n",
    "    \n",
    "    custom_compare(round(mae_solution(y_example_2, y_pred_example_2).item(), 2),\n",
    "                   res_example_2)\n",
    "\n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_general_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_solution(x):\n",
    "    \"\"\"\n",
    "    Принимает на вход вектор численных значений и производит\n",
    "    над ним преобразование согласно логике работы функции Softmax.\n",
    "    \n",
    "    Аргументы:\n",
    "        y: Вектор численных значений. Имеет тип данных `torch.Tensor`.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        Вектор (`torch.Tensor`) вероятностей.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7bf837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_test():\n",
    "    y_example_1 = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "    \n",
    "    res_example_1 = [0.09, 0.24, 0.67]\n",
    "    \n",
    "    custom_compare(to_list(softmax_solution(y_example_1)),\n",
    "                   res_example_1)\n",
    "    \n",
    "    y_example_2 = torch.tensor([-1, 20, 19, -100, 2, 0], dtype=torch.float)\n",
    "    \n",
    "    res_example_2 = [0.0, 0.73, 0.27, 0.0, 0.0, 0.0]\n",
    "    \n",
    "    custom_compare(to_list(softmax_solution(y_example_2)),\n",
    "                   res_example_2)\n",
    "    \n",
    "    print('Тест прошёл успешно!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2763094",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2e414",
   "metadata": {},
   "source": [
    "# Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de830d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1aaa88",
   "metadata": {
    "cellId": "oxzkces261ggunlfndkpm"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = torch.tensor(data[\"data\"])\n",
    "y = torch.tensor(data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc41e2",
   "metadata": {
    "cellId": "uqja6vk3alj6iy4c3n82i"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# TODO: Реализуйте модель нейронной сети и поместите её в эту переменную.\n",
    "#       В качестве функции активации на последнем слое выберите torch.nn.LogSoftmax.\n",
    "model = None\n",
    "\n",
    "# Необходимо сообщить модели, с данными какого типа она будет работать.\n",
    "model = model.to(dtype=X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d51df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3491485",
   "metadata": {
    "cellId": "s306h8ir7rpxzlj36ghoxj"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: Подберите число итераций обучения нейронной сети.\n",
    "#       Значение числа итераций стоит выбрать большим 1000.\n",
    "num_epochs = None\n",
    "\n",
    "# TODO: Создайте оптимизатор SGD аналогично тому, как он задавался в лекции.\n",
    "#       Не забудьте передать в него model.parameters().\n",
    "#       В качестве величины шага обучения (параметр lr) возьмите значение 0.01.\n",
    "optimizer = None\n",
    "\n",
    "# TODO: Задайте функцию потерь. В нашем случае это должна быть torch.nn.NLLLoss.\n",
    "loss_fn = None\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # TODO: Обнулите накопленное значение градиента с помощью фукции zero_grad объекта optimizer.\n",
    "    #       Замените ключевое слово pass на необходимое выражение.\n",
    "    pass\n",
    "    \n",
    "    # TODO: Посчитайте предсказание модели для объектов из матрицы X.\n",
    "    pred = None\n",
    "    # TODO: Посчитайте суммарные потери для предсказанных значений из pred.\n",
    "    loss = None\n",
    "    \n",
    "    # TODO: Рассчитайте градиенты loss по всем параметрам модели с помощью функции backward.\n",
    "    #       Замените ключевое слово pass на необходимое выражение.\n",
    "    pass\n",
    "\n",
    "    # TODO: Произведите шаг оптимизации с помощью функции step объекта optimizer.\n",
    "    #       Замените ключевое слово pass на необходимое выражение.\n",
    "    pass\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        clear_output(True)\n",
    "        fig, ax = plt.subplots(figsize=(30, 10))\n",
    "        plt.title(\"График ошибки\")\n",
    "        plt.plot(losses, \".-\")\n",
    "        plt.xlabel(\"Итерация обучения\")\n",
    "        plt.ylabel(\"Значение ошибки\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3de29",
   "metadata": {},
   "source": [
    "## Получение предсказания на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые данные, которые нужны для проверки корректности решения.\n",
    "test_data = torch.tensor(\n",
    "    [[6.1925, 2.8127, 4.8053, 1.8340],\n",
    "     [6.3122, 3.3084, 4.6696, 1.5903],\n",
    "     [6.4308, 2.7846, 5.6049, 2.0857],\n",
    "     [6.1065, 2.7853, 3.9796, 1.3208],\n",
    "     [5.1890, 4.1195, 1.4894, 0.1041],\n",
    "     [6.4091, 2.7052, 5.3171, 1.9026],\n",
    "     [5.4741, 3.5095, 1.3004, 0.1830],\n",
    "     [6.7288, 3.0913, 4.7038, 1.4960],\n",
    "     [5.0875, 3.5243, 1.4057, 0.3117],\n",
    "     [5.3994, 3.8903, 1.7050, 0.4009],\n",
    "     [5.6904, 4.3916, 1.4684, 0.3964],\n",
    "     [4.9079, 3.0955, 1.4920, 0.1092],\n",
    "     [7.7159, 3.8090, 6.7016, 2.2142],\n",
    "     [4.8113, 3.0182, 1.3959, 0.2815],\n",
    "     [6.4310, 3.2257, 5.2900, 2.3065],\n",
    "     [6.9995, 3.1955, 4.7015, 1.3973],\n",
    "     [5.6823, 2.9997, 4.2251, 1.2014],\n",
    "     [5.5815, 2.7192, 4.1900, 1.2832],\n",
    "     [5.9034, 3.1997, 4.7991, 1.8313],\n",
    "     [5.7005, 2.6195, 3.4773, 0.9757],\n",
    "     [4.9751, 3.5004, 1.3134, 0.2750],\n",
    "     [6.0946, 2.9318, 4.6946, 1.3818],\n",
    "     [5.0014, 3.2270, 1.1918, 0.2007],\n",
    "     [5.8717, 3.0227, 4.2037, 1.5053],\n",
    "     [5.2060, 3.4223, 1.3902, 0.2009],\n",
    "     [4.3859, 3.2013, 1.3159, 0.2079],\n",
    "     [7.3128, 2.8799, 6.3334, 1.8338],\n",
    "     [6.7187, 3.1061, 5.5931, 2.4143],\n",
    "     [6.6812, 3.0036, 4.9912, 1.7009],\n",
    "     [7.1003, 2.9924, 5.8891, 2.0872],\n",
    "     [4.9905, 2.2989, 3.3021, 0.9962],\n",
    "     [6.2052, 3.4357, 5.4059, 2.2973],\n",
    "     [4.4913, 2.2953, 1.3294, 0.3075],\n",
    "     [7.9164, 3.7958, 6.4071, 1.9915],\n",
    "     [4.9946, 3.5099, 1.6099, 0.6029],\n",
    "     [6.9187, 3.1006, 5.4146, 2.0737],\n",
    "     [6.7196, 3.1102, 4.4057, 1.3974],\n",
    "     [6.3969, 2.8016, 5.5884, 2.1988],\n",
    "     [5.1093, 2.5149, 3.0349, 1.0820],\n",
    "     [5.0814, 3.3899, 1.5106, 0.2116],\n",
    "     [5.5119, 4.2125, 1.4162, 0.2252],\n",
    "     [6.5873, 2.8985, 4.6158, 1.3120],\n",
    "     [6.7868, 2.7933, 4.8130, 1.4186],\n",
    "     [5.7971, 2.6743, 3.8844, 1.1489],\n",
    "     [6.4954, 3.1968, 5.0977, 2.0127],\n",
    "     [6.3132, 2.5050, 4.8871, 1.4825],\n",
    "     [4.9923, 3.3990, 1.4873, 0.1776],\n",
    "     [5.8016, 2.6736, 5.1037, 1.8772],\n",
    "     [6.5899, 3.0080, 4.4031, 1.4098],\n",
    "     [6.7034, 3.2995, 5.6906, 2.5213],\n",
    "     [5.5726, 2.5027, 3.9056, 1.1082],\n",
    "     [4.6110, 3.1552, 1.4819, 0.2269],\n",
    "     [5.3962, 3.7292, 1.5056, 0.1840],\n",
    "     [4.6978, 3.1884, 1.2872, 0.2045],\n",
    "     [7.7259, 2.6203, 6.9175, 2.2707],\n",
    "     [4.9117, 3.5911, 1.3559, 0.1051],\n",
    "     [5.5060, 2.4992, 3.9971, 1.2857],\n",
    "     [6.0250, 2.2070, 3.9895, 0.9892],\n",
    "     [6.2824, 2.7039, 4.8852, 1.7950],\n",
    "     [6.5009, 2.9797, 5.4999, 1.8144],\n",
    "     [5.7074, 2.7965, 4.0783, 1.3030],\n",
    "     [7.1991, 3.0009, 5.7894, 1.5942],\n",
    "     [5.4843, 2.3981, 3.6846, 0.9985],\n",
    "     [5.9921, 2.9082, 4.4937, 1.5119],\n",
    "     [5.7057, 2.8921, 4.1759, 1.3012],\n",
    "     [4.9960, 3.3127, 1.3778, 0.1983],\n",
    "     [7.3930, 2.8093, 6.1120, 1.9125],\n",
    "     [4.8980, 3.0966, 1.5072, 0.2077],\n",
    "     [5.7947, 2.6964, 4.0938, 0.9683],\n",
    "     [5.5206, 2.4189, 3.8104, 1.0849],\n",
    "     [6.3227, 3.3981, 5.6103, 2.4238],\n",
    "     [5.3746, 3.4166, 1.5101, 0.4062],\n",
    "     [7.7002, 3.0019, 6.1238, 2.3163],\n",
    "     [7.6668, 2.7952, 6.6920, 2.0174],\n",
    "     [5.7909, 2.7058, 5.1240, 1.8787],\n",
    "     [4.8202, 3.4038, 1.9038, 0.1706],\n",
    "     [4.6180, 3.3850, 1.3792, 0.2890],\n",
    "     [6.0207, 3.3968, 4.4946, 1.5936],\n",
    "     [6.7062, 2.5106, 5.7983, 1.7929],\n",
    "     [7.1862, 3.1946, 6.0065, 1.8011],\n",
    "     [6.9320, 3.1704, 5.6946, 2.3006],\n",
    "     [5.0794, 3.5046, 1.3968, 0.1867],\n",
    "     [5.4282, 2.9711, 4.5280, 1.5053],\n",
    "     [6.2885, 2.8019, 5.0646, 1.5129],\n",
    "     [6.1996, 2.9017, 4.2869, 1.3103],\n",
    "     [6.9157, 3.0832, 5.0973, 2.3123],\n",
    "     [5.5830, 2.7712, 4.9095, 1.9998],\n",
    "     [4.5919, 3.5793, 0.9960, 0.1591],\n",
    "     [6.4994, 2.9805, 5.7897, 2.1949],\n",
    "     [5.6909, 3.8175, 1.7168, 0.3178],\n",
    "     [4.7868, 3.0152, 1.3686, 0.0763],\n",
    "     [5.7133, 2.5093, 4.9902, 1.9970],\n",
    "     [5.7222, 2.7908, 4.4754, 1.2860],\n",
    "     [5.8094, 2.5860, 3.9722, 1.1959],\n",
    "     [6.7882, 3.0047, 5.4856, 2.0806],\n",
    "     [4.9022, 3.0257, 1.3815, 0.2020],\n",
    "     [6.7021, 3.3029, 5.7350, 2.1114],\n",
    "     [4.3860, 2.8866, 1.4093, 0.1907],\n",
    "     [6.1990, 2.2013, 4.4786, 1.5149],\n",
    "     [5.8978, 3.0139, 5.1014, 1.8140],\n",
    "     [6.1015, 2.9760, 4.6244, 1.4117],\n",
    "     [6.1213, 2.9865, 4.9206, 1.7828],\n",
    "     [5.0933, 3.8093, 1.5047, 0.3021],\n",
    "     [6.0865, 2.8123, 4.7077, 1.2249],\n",
    "     [7.6094, 2.9810, 6.6075, 2.0891],\n",
    "     [6.3063, 3.2640, 5.9935, 2.4758],\n",
    "     [5.6007, 3.0030, 4.0734, 1.2912],\n",
    "     [4.6801, 3.1838, 1.5982, 0.1884],\n",
    "     [4.8895, 2.4996, 4.5087, 1.7239],\n",
    "     [5.8046, 2.7879, 5.0710, 2.3901],\n",
    "     [6.0216, 3.0023, 4.7838, 1.8201],\n",
    "     [6.5022, 2.8065, 4.6073, 1.4858],\n",
    "     [7.1887, 3.6003, 6.0947, 2.4976],\n",
    "     [6.9059, 3.0827, 4.8975, 1.5047],\n",
    "     [4.9918, 3.3971, 1.5863, 0.3994],\n",
    "     [6.7818, 3.2047, 5.8888, 2.3061],\n",
    "     [5.0897, 3.6993, 1.5022, 0.4099],\n",
    "     [6.3094, 2.2760, 4.3909, 1.2844],\n",
    "     [4.7939, 3.3883, 1.6162, 0.1956],\n",
    "     [5.1004, 3.3099, 1.6809, 0.4906],\n",
    "     [4.6038, 3.1900, 1.4267, 0.2038],\n",
    "     [6.4056, 3.0822, 5.4876, 1.7860],\n",
    "     [4.7875, 3.0931, 1.5968, 0.2039],\n",
    "     [5.2887, 3.6922, 1.5052, 0.1877],\n",
    "     [5.1729, 2.6834, 3.8810, 1.3679],\n",
    "     [5.6013, 2.9898, 4.4625, 1.5142],\n",
    "     [6.0093, 2.1654, 4.9892, 1.5131],\n",
    "     [4.9704, 3.6133, 1.4107, 0.1914],\n",
    "     [6.0135, 2.6794, 5.1117, 1.5889],\n",
    "     [4.9013, 2.4039, 3.3006, 0.9957],\n",
    "     [6.2933, 2.8898, 5.6077, 1.7835],\n",
    "     [6.1177, 2.5915, 5.6039, 1.3830],\n",
    "     [4.3163, 3.0072, 1.1065, 0.0893],\n",
    "     [5.0958, 3.7942, 1.9179, 0.3851],\n",
    "     [5.1961, 3.4681, 1.5010, 0.1978],\n",
    "     [6.4864, 2.9841, 5.2081, 2.0097],\n",
    "     [6.2862, 2.5160, 4.9928, 1.9029],\n",
    "     [5.3791, 3.4206, 1.7202, 0.2003],\n",
    "     [6.7209, 2.9944, 5.2160, 2.3220],\n",
    "     [5.4871, 2.3214, 4.0096, 1.3024],\n",
    "     [6.4028, 3.1972, 4.5295, 1.4939],\n",
    "     [5.0231, 2.9747, 1.6009, 0.2373],\n",
    "     [4.9869, 1.9933, 3.5222, 1.0113],\n",
    "     [5.0910, 3.8294, 1.5923, 0.2157],\n",
    "     [4.4141, 3.0291, 1.2948, 0.1959],\n",
    "     [6.3924, 2.8996, 4.2981, 1.2741],\n",
    "     [5.3970, 3.8881, 1.3111, 0.3878],\n",
    "     [5.5865, 2.8803, 3.5829, 1.3133],\n",
    "     [5.8151, 3.9625, 1.1992, 0.1796],\n",
    "     [5.5356, 2.6235, 4.3694, 1.1910]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель для каждого объекта из тестовых данных возвращает вектор из 3-х численных значений,\n",
    "# каждое из которых является логарифмом вероятности принадлежности объекта конкретному классу.\n",
    "log_probs = model(test_data)\n",
    "\n",
    "# Чтобы получить не логарифмы вероятностей, а сами вероятности,\n",
    "# нужно поэлементно возвести экспоненту в степень логарифмов вероятности.\n",
    "pred_class_probs = log_probs.exp()\n",
    "\n",
    "# Для того чтобы понять, к какому классу модель отнесла тот или иной объект,\n",
    "# нужно понять, какая координата соответствующего вектора предсказанных веряотностей имеет\n",
    "# наибольшее значение. То есть к какому классу с точки зрения модели объект\n",
    "# относится с наибольшей вероятностью.\n",
    "# Чтобы выбрать номер координаты с наибольшим значением\n",
    "# в каждой строчке матрицы log_probs, воспользуемся функцией torch.argmax.\n",
    "# Значение ключевого парамтера dim указывает на то, что мы ищем наибольшее\n",
    "# значение именно в каждой строчке.\n",
    "pred_class = torch.argmax(log_probs, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeaf873",
   "metadata": {},
   "source": [
    "#### Значение, которое нужно отправить в систему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd38ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(to_list(pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

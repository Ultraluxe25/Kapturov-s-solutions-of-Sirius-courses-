{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек.\n",
    "\n",
    "!pip3 install xmltodict -q\n",
    "!pip3 install albumentations -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек.\n",
    "\n",
    "import xmltodict\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from albumentations import Compose, Resize, HorizontalFlip, RandomBrightnessContrast, BboxParams\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фиксируем устройство, на котором будут производиться вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем небольшую часть датасета [Fruits](https://universe.roboflow.com/fruitsdetection/fruits-by-yolo) для дальнейшего изучения.\n",
    "\n",
    "Из датасета возьмём только 4 класса изображений, чтобы снизить объём данных, с которыми мы будем работать. Данный датасет часто служит примером для демонстрации возможностей детекции, например, в статьях и демо моделей YOLO. Каждое изображение в датасете — это фото определенного фрукта или нескольких фруктов.\n",
    "\n",
    "Данные для работы в рамках этого модуля доступны [по ссылке](https://edu.sirius.online/noo-back/files/8a3de946c0734dd18724f5fc9e089b2f35f14dfe.zip). Скачайте архив (его размер — 30 Мб), распакуйте и поместите полученную папку `data` в директорию с блокнотом Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на какой-нибудь пример изображения из датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'banana_2'\n",
    "plt.imshow(np.array(Image.open(f'data/train/{name}.jpg')));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в задаче детекции важно не только изображение, но и его прямоугольник. Давайте посмотрим, в каком виде он сохранен в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'banana_2'\n",
    "\n",
    "with open(f'data/train/{name}.xml') as f:\n",
    "    tmp = f.read()\n",
    "\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По умолчанию прямоугольник сохранён в формате `xml`. Для работы с файлами `xml` мы будем использовать библиотеку `xmltodict`. Она позволяет превратить файл `xml` в обычный Python-словарь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'banana_2'\n",
    "\n",
    "with open(f'data/train/{name}.xml') as f:\n",
    "    tmp = f.read()\n",
    "\n",
    "tmp = xmltodict.parse(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь чётко видно, что в датасете каждый прямоугольник описывается координатами двух его противоположных вершин: $(x_{min}, y_{min})$, $(x_{max}, y_{max})$.\n",
    "\n",
    "Заметим, что это не единственный способ кодирования координат прямоугольника. Также распространенным является формат: $[x_{center}, y_{center}, width, height]$ — даются координаты центра прямоугольника, а также его относительные (по отношению к длине или высоте самого изображения) ширина и высота."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условие**\n",
    "\n",
    "Реализуйте функцию, которая берёт изображение из датасета и рисует его вместе с прямоугольником. Для этого используйте шаблон в ячейке ниже, заполнив в нём все места, помеченные ключевым словом TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_picture_with_bbox(picture_name):\n",
    "    \"\"\"\n",
    "    Отрисовывает изображение из датасета и его прямоугольник.\n",
    "    \n",
    "    Аргументы:\n",
    "        picture_name: Название изображения.\n",
    "        \n",
    "    Возвращаемое значение:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Считываем xml-файл с прямоугольником для нужного изображения.\n",
    "    with open(f'data/train/{picture_name}.xml') as f:\n",
    "        tmp = f.read()\n",
    "    tmp = xmltodict.parse(tmp)\n",
    "\n",
    "    # TODO: Достаём из словаря координаты вершин прямоугольника.\n",
    "    coordinates = ...\n",
    "\n",
    "    # TODO: Определение координат вершин прямоугольника.\n",
    "    x_min = ...\n",
    "    y_min = ...\n",
    "    x_max = ...\n",
    "    y_max = ...\n",
    "\n",
    "    # Вывод изображения на экран.\n",
    "    plt.imshow(np.array(Image.open(f'data/train/{picture_name}.jpg')))\n",
    "    plt.vlines(x_min, y_min, y_max, color='red')\n",
    "    plt.vlines(x_max, y_max, y_min, color='red')\n",
    "    plt.hlines(y_min, x_min, x_max, color='red')\n",
    "    plt.hlines(y_max, x_max, x_min, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что нужно внести в систему**\n",
    "\n",
    "Теперь проверим, что функция работает корректно. Возьмем ту же картинку банана и нарисуем картинку и прямоугольник. В качестве решения задания выберите на платформе картинку, которая совпадает с полученной вами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_picture_with_bbox('banana_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь приступим к работе с датасетом с помощью pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала вам будет необходимо скачать Python-модуль `dataset.py`, который принимает в себя датасет Fruits и сам создает pytorch-датасет для работы с ним. Модуль доступен [по ссылке](https://edu.sirius.online/noo-back/files/16f7612e802d1a434e930da41046f3c7ce394b3c.py) (6 Кб).\n",
    "\n",
    "Чтобы модуль стал доступен из этого блокнота, необходимо поместить скачанный файл `dataset.py` в одну директорию с блокнотом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем модуль из скачанного файла, а также создадим словарь, который ставит в соответствие классам картинок их индексы, чтобы их закодировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import FruitDataset\n",
    "class2tag = {\"apple\": 1, \"orange\": 2, \"banana\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все картинки должны иметь одинаковый размер, чтобы работать с ними было удобно. Определим этот размер заранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH, HEIGHT = 448, 448"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед обучением нашей модели нам будет необходимо провести аугментацию имеющихся изображений. Это поможет нам бороться с проблемой переобучения модели.\n",
    "\n",
    "Если мы применим аугментации к картинкам из нашего датасета, то они изменятся. Однако измениться должны не только сами изображения, но и их прямоугольники (которые также называют bounding box). Получается, когда мы меняем положение банана в пространстве, мы должны применить аналогичное преобразование и к прямоугольнику на этом изображении.\n",
    "\n",
    "Задача аугментации изображений вместе с их прямоугольниками уже решена в библиотеке `albumentations`. В ней собраны аугментации, применение которых к данным автоматически меняет прямоугольники так, чтобы они соответствовали изменениям. Попробуем создать датасет с аугментациями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "        # изменить размер изображения\n",
    "        Resize(WIDTH, HEIGHT),\n",
    "        # отражение по горизонтали \n",
    "        HorizontalFlip(p=0.5),\n",
    "        # меняем яркость и контрастность изображения\n",
    "        RandomBrightnessContrast(p=0.1)\n",
    "    ],\n",
    "    # указываем на наличие bounding_box\n",
    "    bbox_params=BboxParams(format='yolo',\n",
    "                           label_fields=['class_labels']))\n",
    "\n",
    "val_transform = Compose([\n",
    "        Resize(WIDTH, HEIGHT),\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomBrightnessContrast(p=0.2),\n",
    "    ],\n",
    "    bbox_params=BboxParams(format='yolo',\n",
    "                           label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь соберём сами датасеты для обучения и валидации.\n",
    "\n",
    "Как вы знаете, внутри YOLO каждое изображение разбивается на `S x S` блоков, каждый из которых генерирует `B` прямоугольников-кандидатов. Объекты на изображении могут относиться к одному из `C` классов. Именно данные параметры и передаются во FruitDataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет и даталоадеры по шаблону ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Саначала нужно создать обучающий и валидационный датасеты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FruitDataset(\n",
    "    transforms=train_transform,    # Аугментации обучающей выборки.\n",
    "    class2tag=class2tag,           # Словарь классов и их индексов.\n",
    "    data_dir=\"data/train/\",        # Путь к данным для обучения.\n",
    "    S=7, B=2, C=3,                 # Мы хотим иметь 7 секций по 2 прямоугольника в каждой.\n",
    "    device=device                  # Перемещаем тензоры на соответствующее устройство.\n",
    "    )\n",
    "\n",
    "val_dataset = FruitDataset(\n",
    "    transforms=val_transform,      # Аугментации валидационной выборки.\n",
    "    class2tag=class2tag,           # Словарь классов и их индексов.\n",
    "    data_dir=\"data/test/\",         # Путь к данным для валидации.\n",
    "    S=7, B=2, C=3,                 # Структура аналогична обучающей выборке.\n",
    "    device=device                  # Перемещаем тензоры на соответствующее устройство.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из датасетов нужно создать даталоадеры — генераторы, которые формируют батчи картинок и выдают их. Если создавать их с флагом `shuffle=True`, то на каждой эпохе содержание батчей будет отличаться - объекты каждый раз будут перемешиваться. Также, с таким флагом нет никакой уверенности, что будет в каждом отдельном батче. Потому для стабильности необходимо зафиксировать все возможные случайности с помощью функции в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим из датасетов даталоадеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,            # Обучающий датасет.\n",
    "    batch_size=4,                     # Размер батча.\n",
    "    shuffle=True,                     # Нужно ли перемешивать объекты.\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,              # Валидационный датасет.\n",
    "    batch_size=4,                     # Размер батча.\n",
    "    shuffle=False,                    # Нужно ли перемешивать объекты.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на изображения после аугментаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)\n",
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch[0][2].cpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получившееся изображение выглядит довольно странно. Давайте поймём, что произошло. Изображение было отражено, и в нём изменились яркость и контрастность. Человеческому глазу с ходу трудно понять, что происходит на изображении. Однако для обучения моделей машинного обучения такая картинка вполне годится.\n",
    "\n",
    "Тем не менее изображение можно вернуть в исходное состояние. Используем для этого модуль из `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.ToPILImage()(batch[0][2].cpu().numpy().reshape(WIDTH, HEIGHT, 3).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасеты готовы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь поймём, как мы будем сравнивать прямоугольники. Для этого можно использовать рассмотреную в лекции метрику IoU — Intersection over Union. Данная метрика проста для понимания: берем площадь прямоугольника из пересечения предсказанного и правильного прямоугольников и делим её на площадь объединения двух прямоугольников. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условие**\n",
    "\n",
    "Реализуйте функцию для вычисления значения метрики IoU на основе шаблона в ячейке ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(predicted_bbox, gt_bbox):\n",
    "    \"\"\"\n",
    "    Вычисляет значение Intersection over Union для двух прямоугольников\n",
    "    \n",
    "    Аргументы:\n",
    "        predicted_bbox: Предсказанный прямоугольник в формате [x_min, y_min, x_max, y_max].\n",
    "        gt_bbox: Правильный прямоугольник в формате [x_min, y_min, x_max, y_max].\n",
    "\n",
    "    Возвращаемое значение:\n",
    "        Значение Intersection over Union.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Пересечение двух прямоугольников, если оно есть, всегда будет прямоугольником.\n",
    "    #       Вычислите координаты прямоугольника, который будет являться пересечением двух прямоугольников.\n",
    "    intersection_x_min = ...\n",
    "    intersection_y_min = ...\n",
    "    intersection_x_max = ...\n",
    "    intersection_y_max = ...\n",
    "\n",
    "    # TODO: Вычислите площадь пересечения (может быть нулевой).\n",
    "    intersection_area = ...\n",
    "\n",
    "    # TODO: Вычислите площадь предсказанного прямоугольника.\n",
    "    area_pred = ...\n",
    "\n",
    "    # TODO: Вычислите площадь правильного прямоугольника.\n",
    "    area_gt = ...\n",
    "\n",
    "    # TODO: Вычислите площадь объединения (помните, что пересечение дважды входит в сумму\n",
    "    #       площадей двух прямоугольников).\n",
    "    union_area = ...\n",
    "\n",
    "    # TODO: Вычислите значение IoU.\n",
    "    iou = ...\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно проверить, что все работает правильно. Возьмем уже известную нам картинку банана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_picture_with_bbox('banana_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим сюда еще один прямоугольник. В рамках тестирования функции будем считать, что именного его наша модель и предсказала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_picture_with_bbox('banana_2')\n",
    "pred_bbox = [30, 150, 500, 700]\n",
    "plt.vlines(30, 150, 750, color='blue')\n",
    "plt.vlines(500, 750, 150, color='blue')\n",
    "plt.hlines(150, 30, 500, color='blue')\n",
    "plt.hlines(750, 500, 30, color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/train/banana_2.xml') as f:\n",
    "    tmp = f.read()\n",
    "tmp = xmltodict.parse(tmp)\n",
    "\n",
    "coordinates = tmp['annotation']['object']['bndbox']\n",
    "\n",
    "x_min = int(coordinates['xmin'])\n",
    "y_min = int(coordinates['ymin'])\n",
    "x_max = int(coordinates['xmax'])\n",
    "y_max = int(coordinates['ymax'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что нужно внести в систему**\n",
    "\n",
    "Найдите IoU для этих двух прямоугольников. В качестве ответа выведите число, округлив его до 3 знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bbox = [x_min, y_min, x_max, y_max]\n",
    "print(round(intersection_over_union(target_bbox, pred_bbox), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь скачайте веса предобученной модели. Это не совсем модель YOLO, так как настоящая такая модель весит очень много, что делает ее использование затруднительным в условиях ограниченных ресурсов.\n",
    "\n",
    "Представленная модель является облегчённой версией YOLO, которая показывает несколько более скромные результаты, но все же даёт возможность довольно неплохо определять прямоугольники для изображений.\n",
    "\n",
    "[Ссылка](https://disk.yandex.ru/d/vejo44MeMiaO6w) (**важно**, что модель всё равно весит (!) 840 Мб) на скачивание модели. Файл с моделью нужно разместить в одной директории с блокнотом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведена архитектура той модели, которую вы скачали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Свёрточный блок.\n",
    "class CNNBlock(nn.Module): \n",
    "    def __init__(self, in_channels, out_channels, is_max_pool=False, **kwargs):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.is_max_pool = is_max_pool\n",
    "        self.max_pool = nn.MaxPool2d(2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leakyrelu(self.batchnorm(self.conv(x)))\n",
    "        if self.is_max_pool:\n",
    "            x = self.max_pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Сама облегчённая версия YOLO.\n",
    "class YOLO(nn.Module):\n",
    "    def __init__(self,\n",
    "                 S=7,  # S * S - количество ячеек на которые разбивается изображение.\n",
    "                 B=2,  # Количество прямоугольников-кандидатов в каждой ячейке.\n",
    "                 C=3,  # Количество классов.\n",
    "                 batch_size=1):\n",
    "\n",
    "        super(YOLO, self).__init__()\n",
    "\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        self.conv1 = CNNBlock(in_channels=3, out_channels=64, kernel_size=7, is_max_pool=True, stride=2, padding=2)\n",
    "        self.conv2 = CNNBlock(in_channels=64, out_channels=32, kernel_size=3, is_max_pool=True)\n",
    "        self.conv3 = CNNBlock(32, 16, kernel_size=3)\n",
    "\n",
    "        self.fc1 = nn.Linear(43264, 100 * S * S)\n",
    "        self.fc2 = nn.Linear(100 * S * S, S * S * (5 * B + C))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if len(x.shape) == 3:\n",
    "            # на случай если всего один объект на вход, а не батч => батч размера 1\n",
    "            x = torch.unsqueeze(x, dim=0)\n",
    "        x = x.reshape(-1, 3, 448, 448)\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.reshape((batch_size, self.S, self.S, (self.B * 5 + self.C)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель из файла.\n",
    "model = torch.load('best_model_50.h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть модель с весами, которые уже подстроились под наш датасет. Модель обучалась на наших данных в течение 50 эпох."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на то, что модель выдает на выходе для случайной картинки из валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=5,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(1)\n",
    "batch = next(iter(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch[0][1].cpu()\n",
    "target = batch[1][1].cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на случайное изображение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.ToPILImage()(image.numpy().reshape(WIDTH, HEIGHT, 3).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На изображении должен быть апельсин. Это нам гарантирует то, что в процессе извлечения данных из датасета мы с помощью функции `seed_everything` фиксировали случайность выбора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условие**\n",
    "\n",
    "С помощью модели YOLO, которая хранится в переменной `model`, сделайте предсказание для изображения `image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Необходимо реализовать предсказание модели для изображения `image`.\n",
    "preds = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучим, как выглядит наше предсказание."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результатом работы модели для одного объекта, как было рассмотрено в лекции, является набор блоков. Каждому из них сопоставлены прямоугольники-кандидаты и набор вероятностей принадлежностей блока различным классам. Однако из-за того, что `model` делает предсказание для целого батча, в выходной тензор добавляется внешняя размерность. \n",
    "\n",
    "То есть ожидаемый размер выходного тензора — $(N_{batches}, \\ S, \\ S, \\ (5 \\cdot B + C))$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что нужно внести в систему**\n",
    "\n",
    "В качестве ответа на задание найдите среднее значение по всему тензору предсказанных значений и округлите его до 3 знаков после запятой. Для этого заполните пропуск в ячейке ниже и запустите её.\n",
    "\n",
    "**Рекомендации по решению**\n",
    "\n",
    "Для того чтобы достать из тензора конкретное число, вам может понадобиться функция `item`. Она превращает тензор из одного зачения в это значение:\n",
    "\n",
    "```python3\n",
    "a = torch.tensor(1)\n",
    "\n",
    "print(a)         # tensor(1)\n",
    "print(a.item())  # 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Необходимо вычислить среднее значение по всему тензору предсказанных\n",
    "#       значений и округлить его до 3 знаков после запятой. \n",
    "round(..., 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работать с таким представлением прямоугольников трудно. Поэтому мы преобразуем полученный тензор к привычному нам виду прямоугольника.\n",
    "\n",
    "Для этого воспользуемся уже реализованным Python-модулем `boxes`, который доступен [по ссылке](https://edu.sirius.online/noo-back/files/03f641023a82cd23dfa5b5d0c38e2c4f2f86ea71.py). Так же, как и раньше, нужно скачать файл по ссылке и поместить его в директорию с блокнотом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boxes import get_bound_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `get_bound_boxes` сама сделает с помощью `model` предсказание для изображения, а также обработает выход — возьмёт все возможные прямоугольники и проверит их на пересечения (не имеет смысла выводить два прямоугольника, которые сильно пересекаются)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(123)\n",
    "pred_bbox = get_bound_boxes(images=image, model=model, iou=intersection_over_union, iou_threshold=.5, conf_threshold=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно преобразовать предсказанные прямоугольники в используемый нами формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bboxes = []\n",
    "for box in pred_bbox:\n",
    "    x_min = abs(box[0] * WIDTH - int((box[2] * WIDTH / 2)))\n",
    "    x_max = abs(box[0] * WIDTH + int((box[2] * WIDTH / 2)))\n",
    "    y_min = abs(box[1] * HEIGHT - int((box[3] * HEIGHT/ 2)))\n",
    "    y_max = abs(box[1] * HEIGHT + int((box[3] * HEIGHT/ 2)))\n",
    "    bbox = [x_min, y_min, x_max, y_max]\n",
    "    predictions_bboxes += [bbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правильные прямоугольники тоже нужно привести к данному формату."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bboxes = []\n",
    "for cell in target.reshape(7*7, 13):\n",
    "    for box_ind in range(0, 10, 5):\n",
    "        pos_box = cell[box_ind:box_ind+5]\n",
    "        if sum(pos_box) != 0:\n",
    "            x_min = pos_box[0] * WIDTH - int((pos_box[2] * WIDTH / 2))\n",
    "            x_max = pos_box[0] * WIDTH + int((pos_box[2] * WIDTH / 2))\n",
    "            y_min = pos_box[1] * HEIGHT - int((pos_box[3] * HEIGHT/ 2))\n",
    "            y_max = pos_box[1] * HEIGHT + int((pos_box[3] * HEIGHT/ 2))\n",
    "            bbox = [x_min, y_min, x_max, y_max]\n",
    "            target_bboxes += [bbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем нарисовать настоящий прямоугольник и предсказанный нашей моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pic_with_bboxes(picture, tgt_bbox, pred_bbox):\n",
    "    img = torchvision.transforms.ToPILImage()(image.numpy().reshape(WIDTH, HEIGHT, 3).astype(np.uint8))\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.vlines(pred_bbox[0], pred_bbox[1], pred_bbox[3], color='blue')\n",
    "    plt.vlines(pred_bbox[2], pred_bbox[3], pred_bbox[1], color='blue')\n",
    "    plt.hlines(pred_bbox[1], pred_bbox[0], pred_bbox[2], color='blue')\n",
    "    plt.hlines(pred_bbox[3], pred_bbox[2], pred_bbox[0], color='blue')\n",
    "\n",
    "    plt.vlines(tgt_bbox[0], tgt_bbox[1], tgt_bbox[3], color='red')\n",
    "    plt.vlines(tgt_bbox[2], tgt_bbox[3], tgt_bbox[1], color='red')\n",
    "    plt.hlines(tgt_bbox[1], tgt_bbox[0], tgt_bbox[2], color='red')\n",
    "    plt.hlines(tgt_bbox[3], tgt_bbox[2], tgt_bbox[0], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pic_with_bboxes(image, target_bboxes[0], predictions_bboxes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что наше предсказание (синий прямоугольник) пересекается с правильным прямоугольником (красный прямоугольник). Однако ошибка предсказания всё равно существенная.\n",
    "\n",
    "Давайте поймём, насколько наше предсказание далеко от реальности. Для этого воспользуемся метрикой IoU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условие**\n",
    "\n",
    "Рассчитайте значение метрики IoU для прямоугольников, которые получились в `predictions_bboxes` и `target_bboxes`.\n",
    "\n",
    "Если вдруг в `predictions_bboxes` и/или `target_bboxes` есть больше одного прямоугольника, то считайте метрику только для двух первых прямоугольников в массиве(-ах). Аналогично тому, как строилось изображение выше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что нужно внести в систему**\n",
    "\n",
    "В качестве ответа на задание введите значение метрики, округлённое до 3-х знаков после запятой. Для этого заполните пропуск в ячейке ниже и запустите её."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Необходимо вычислить  значение метрики IoU и округлить его до 3 знаков после запятой. \n",
    "round(..., 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
